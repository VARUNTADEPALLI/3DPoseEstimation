{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-Xudk_weQUA6YLX4Prsuo_6s576At0EP","timestamp":1713898991709}],"authorship_tag":"ABX9TyOjn6FlSCCR+kC25JwKIxac"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose\n","\n","  [arxiv](https://arxiv.org/abs/1811.12004) | [Github](https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch)\n","\n","  Osokin, Daniil\n","\n","# A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose\n","\n","   [arxiv](https://arxiv.org/pdf/2111.12696) | [Github](https://github.com/zczcwh/GTRS)\n","\n","   Zheng, Ce and Mendieta, Matias and Wang, Pu and Lu, Aidong and Chen, Chen\n","\n"],"metadata":{"id":"V-ZBfi8aICer"}},{"cell_type":"markdown","source":["This Colab notebook implements the GTRS repository, which provides a Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose, found at https://github.com/zczcwh/GTRS/tree/main. It also integrates the Lightweight OpenPose model for 2D pose detection, available at https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch/tree/master."],"metadata":{"id":"LhyF-u6SsYpD"}},{"cell_type":"markdown","source":["To use Conda in Google Colab, we start by installing Miniconda. This provides the necessary environment management and package installation capabilities."],"metadata":{"id":"npV-sPinr7aH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9xgIQo2T4MW"},"outputs":[],"source":["!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n"]},{"cell_type":"markdown","source":["Now, we'll update Conda and create a new Conda environment to ensure that the required packages are installed within this isolated environment. This step is crucial for managing dependencies efficiently.\n"],"metadata":{"id":"Zr-73ENwsAzH"}},{"cell_type":"code","source":["    # Update conda\n","!conda update -n base -c defaults conda -y\n","\n","\n","import sys\n","_ = (sys.path\n","          .append(\"/usr/local/lib/python3.9/site-packages\"))\n","\n","  # Create a new environment\n","!conda create --name gtrs python=3.9 -y"],"metadata":{"id":"QjfIS_cJT848"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# we activate the conda environment named gtrs"],"metadata":{"id":"P7tR0AXVKS7t"}},{"cell_type":"code","source":["!conda init bash\n","!source activate gtrs"],"metadata":{"id":"mePtwEZsT-68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!conda update -n base -c defaults conda -y"],"metadata":{"id":"leG_N75RUBcl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Download project from official repos"],"metadata":{"id":"UvJXhs7iKp_r"}},{"cell_type":"markdown","source":["The next step involves downloading the GTRS project from the official repository. If you prefer not to set up or organize the project structure manually, you can download the pre-organized files from the Google Drive link: https://drive.google.com/drive/folders/1PiHa7IdhD0kxDhs8uN61Xzwhgxg65yrS?usp=sharing. This link contains all the necessary files, arranged according to the structure specified in the official GitHub repository."],"metadata":{"id":"N3GWu7nysHBs"}},{"cell_type":"markdown","source":["There a few changes required to be made before running the inference on GTRS.\n","\n","1. change the file locations in the config.py file in the core folder of the lib directory. The files paths present in the config.py file are according to our system and drive. Please make sure to change them in accordance to yours."],"metadata":{"id":"M3ph1BAAiAVN"}},{"cell_type":"markdown","source":["Installing the required packages listed to prepare for the demo\n"],"metadata":{"id":"TMdYu44jM49n"}},{"cell_type":"code","source":["!pip install opencv-python\n","!pip install transforms3d\n","!pip install pycocotools\n","!pip install git+https://github.com/scottandrews/chumpy.git@fe51783e0364bf1e9b705541e7d77f894dd2b1ac\n","!pip install pyrender\n","!pip install trimesh\n","!pip install pyyaml\n","!pip install easydict\n","!pip install tqdm"],"metadata":{"id":"qQf-bwUPUB30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["requirements_file_path = '/content/drive/MyDrive/GTRS-mains/requirements.txt'\n","\n","# Read the contents of the requirements.txt file\n","with open(requirements_file_path, 'r') as file:\n","    requirements = file.read().splitlines()\n","\n","# Install packages one by one\n","for requirement in requirements:\n","    try:\n","        !pip install {requirement}\n","    except Exception as e:\n","        print(f\"Failed to install {requirement}: {e}\")"],"metadata":{"id":"zXh0xu_rUDo1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Installation of the uninstalled packages"],"metadata":{"id":"AYBYALJzXSkz"}},{"cell_type":"markdown","source":["After the above two cells are run, you might see that a portion of the packages would'nt be installed because of version mismatch and other reasons. So the below commands will help in installing the rest packages"],"metadata":{"id":"7GOX258yNBFu"}},{"cell_type":"code","source":["!conda install cctbx202112::brotli\n","!conda install anaconda::matplotlib-base\n","!conda install conda-forge::yaml\n","!conda install conda-forge::xorg-libxdmcp\n","!conda install cctbx202211::xorg-libxau\n","!pip install torchaudio\n","!conda install conda-forge::sip\n","!pip install --upgrade setuptools\n","!conda install conda-forge::qt\n","!conda install pytorch::pytorch-mutex\n","!conda install conda-forge::python_abi\n","!pip install PyQt5\n","!conda install anaconda::mkl_fft\n","!conda install anaconda::mkl-service\n","!conda install anaconda::libuv\n","!conda install cctbx202008::libgfortran-ng\n","!conda install cctbx202208::lcms2\n","!conda install cctbx202008::jpeg\n","!conda install pytorch::ffmpeg\n","!pip install --upgrade cython\n","!pip install --upgrade pip setuptools\n","!pip install xtcocotools\n","!conda install anaconda::glib\n","!conda install cctbx202112::glib\n","!conda install anaconda::giflib\n","!conda install cctbx202112::fontconfig\n","!conda install pytorch::ffmpeg\n","!conda install conda-forge::dbus"],"metadata":{"id":"W10a2U1iUHpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall torch\n","!pip cache purge\n","!pip install torch torchvision --pre -f https://download.pytorch.org/whl/nightly/cu121/torch_nightly.html\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"],"metadata":{"id":"yRQ3g4XpUrfN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Once the packages are installed, you can proceed to run the inference for 2D pose detection using the Lightweight OpenPose model. This step is essential for identifying the key points of the human pose in the input image, which will be used for 3D mesh reconstruction"],"metadata":{"id":"q5AH7PcgXjZb"}},{"cell_type":"markdown","source":["https://drive.google.com/drive/folders/16913ljV7Tt6FmRR7uGaCLyIAe649mdeS?usp=sharing is the drive link for the 2D pose detection. All the required files are downloaded and moved torresponding directories. Once the download is complete, please mount them to your drive to run the inference in colab"],"metadata":{"id":"oRR7G_a4X_f3"}},{"cell_type":"markdown","source":["The infernece requires a set of packages as per the official repo. Install them with the below command"],"metadata":{"id":"4MEa12EiU2Zr"}},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/TransPose/requirements.txt"],"metadata":{"id":"5m5SnHfZUrcU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Once the package requirement is satisfied, the infernce can be run. But before that certain changes have to be made.\n","\n","\n","1. change the location of where the result.npy shoulbe saved at line number 142 at demo.py\n","\n","2. change the location of where the output image on which the 2pose is drawn at line number 151 at demo.py"],"metadata":{"id":"5aK_GV6gY38M"}},{"cell_type":"code","source":["!python /content/drive/MyDrive/lightweight/demo.py --checkpoint-path /content/drive/MyDrive/checkpoint_iter_370000.pth --images /content/drive/MyDrive/lightweight/input.jpeg"],"metadata":{"id":"G7fLFkBcUrZU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After running the infernce for the 2D pose Detetction, you would see a result.npy file in the folder structure. We pass the file path as a parameter as hown below for the input_pose along with the input image. Please make sure to update the file paths accordingly. Once the inference runs successfully you would see the 3D Mesh generated on the human body as per the pose in the ouput images"],"metadata":{"id":"5toM3UkSVf_N"}},{"cell_type":"code","source":["!python /content/drive/MyDrive/GTRS-mains/demo/run.py --gpu 0 --input_pose /content/drive/MyDrive/lightweight/result.npy --input_img /content/drive/MyDrive/lightweight/input.jpeg"],"metadata":{"id":"X0QBBm4wUrWT"},"execution_count":null,"outputs":[]}]}